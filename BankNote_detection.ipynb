{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "def read_dataset():\n",
    "    df = pd.read_csv(\"C:\\\\Users\\\\raprabhu\\\\Downloads\\\\bank_note_data.csv\")\n",
    "    # print(len(df.columns))\n",
    "    X = df[df.columns[0:4]].values\n",
    "    y = df[df.columns[4]]\n",
    " \n",
    "    # Encode the dependent variable\n",
    "    Y = one_hot_encode(y)\n",
    "    print(X.shape)\n",
    "    return (X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1372, 4)\n",
      "(1097, 4)\n",
      "(1097, 2)\n",
      "(275, 4)\n",
      "n_dim 4\n",
      "epoch :  0  -  cost:  0.7298712  - MSE:  5.03613651939194 - Train Accuracy:  0.562443\n",
      "epoch :  1  -  cost:  0.6181565  - MSE:  4.648981835041076 - Train Accuracy:  0.74567\n",
      "epoch :  2  -  cost:  0.58418995  - MSE:  4.541621264855894 - Train Accuracy:  0.75113946\n",
      "epoch :  3  -  cost:  0.57169133  - MSE:  4.500362686795284 - Train Accuracy:  0.75022787\n",
      "epoch :  4  -  cost:  0.56581384  - MSE:  4.485289647018821 - Train Accuracy:  0.7538742\n",
      "epoch :  5  -  cost:  0.5627043  - MSE:  4.480411930222482 - Train Accuracy:  0.7547858\n",
      "epoch :  6  -  cost:  0.56040984  - MSE:  4.478872927021018 - Train Accuracy:  0.7547858\n",
      "epoch :  7  -  cost:  0.5550728  - MSE:  4.484967578911131 - Train Accuracy:  0.7584321\n",
      "epoch :  8  -  cost:  0.55011016  - MSE:  4.489329819530545 - Train Accuracy:  0.76299\n",
      "epoch :  9  -  cost:  0.54254264  - MSE:  4.494033754965253 - Train Accuracy:  0.76845944\n",
      "epoch :  10  -  cost:  0.5358941  - MSE:  4.498080994466606 - Train Accuracy:  0.7739289\n",
      "epoch :  11  -  cost:  0.5284665  - MSE:  4.4999042991174205 - Train Accuracy:  0.7784868\n",
      "epoch :  12  -  cost:  0.52116466  - MSE:  4.495282607509408 - Train Accuracy:  0.7848678\n",
      "epoch :  13  -  cost:  0.5134971  - MSE:  4.486892241250695 - Train Accuracy:  0.79124886\n",
      "epoch :  14  -  cost:  0.50680625  - MSE:  4.479833672804076 - Train Accuracy:  0.793072\n",
      "epoch :  15  -  cost:  0.5012247  - MSE:  4.47361906467516 - Train Accuracy:  0.7948952\n",
      "epoch :  16  -  cost:  0.4938853  - MSE:  4.460175491724205 - Train Accuracy:  0.7967183\n",
      "epoch :  17  -  cost:  0.48316258  - MSE:  4.4415869572630795 - Train Accuracy:  0.8003646\n",
      "epoch :  18  -  cost:  0.47078335  - MSE:  4.424947720864667 - Train Accuracy:  0.8195078\n",
      "epoch :  19  -  cost:  0.45646623  - MSE:  4.412862195107757 - Train Accuracy:  0.83044666\n",
      "epoch :  20  -  cost:  0.4427387  - MSE:  4.40491504743113 - Train Accuracy:  0.8386509\n",
      "epoch :  21  -  cost:  0.43070933  - MSE:  4.393363071675701 - Train Accuracy:  0.8441203\n",
      "epoch :  22  -  cost:  0.41559368  - MSE:  4.388473111269915 - Train Accuracy:  0.857794\n",
      "epoch :  23  -  cost:  0.40583563  - MSE:  4.379413664608825 - Train Accuracy:  0.8596171\n",
      "epoch :  24  -  cost:  0.39671847  - MSE:  4.371784608264568 - Train Accuracy:  0.86599815\n",
      "epoch :  25  -  cost:  0.38590735  - MSE:  4.364230402253111 - Train Accuracy:  0.87055606\n",
      "epoch :  26  -  cost:  0.37530878  - MSE:  4.359442451918603 - Train Accuracy:  0.8732908\n",
      "epoch :  27  -  cost:  0.36827087  - MSE:  4.356975613012161 - Train Accuracy:  0.8760255\n",
      "epoch :  28  -  cost:  0.36259586  - MSE:  4.35429367332083 - Train Accuracy:  0.8769371\n",
      "epoch :  29  -  cost:  0.35754138  - MSE:  4.352312910945077 - Train Accuracy:  0.8787603\n",
      "epoch :  30  -  cost:  0.35291636  - MSE:  4.350805719994034 - Train Accuracy:  0.8796718\n",
      "epoch :  31  -  cost:  0.349167  - MSE:  4.352183651185146 - Train Accuracy:  0.8805834\n",
      "epoch :  32  -  cost:  0.3453307  - MSE:  4.352665373186019 - Train Accuracy:  0.881495\n",
      "epoch :  33  -  cost:  0.34125823  - MSE:  4.352551264077384 - Train Accuracy:  0.8824066\n",
      "epoch :  34  -  cost:  0.33650944  - MSE:  4.351517984356764 - Train Accuracy:  0.8833181\n",
      "epoch :  35  -  cost:  0.33001265  - MSE:  4.349601296455575 - Train Accuracy:  0.8842297\n",
      "epoch :  36  -  cost:  0.3228097  - MSE:  4.34592179315918 - Train Accuracy:  0.88605285\n",
      "epoch :  37  -  cost:  0.31576434  - MSE:  4.341577717971972 - Train Accuracy:  0.89061075\n",
      "epoch :  38  -  cost:  0.30863318  - MSE:  4.338277404603007 - Train Accuracy:  0.89516866\n",
      "epoch :  39  -  cost:  0.2998473  - MSE:  4.337333860303538 - Train Accuracy:  0.898815\n",
      "epoch :  40  -  cost:  0.29080224  - MSE:  4.341372468706366 - Train Accuracy:  0.90701914\n",
      "epoch :  41  -  cost:  0.28263664  - MSE:  4.35060285608724 - Train Accuracy:  0.91157705\n",
      "epoch :  42  -  cost:  0.27244556  - MSE:  4.353545504875373 - Train Accuracy:  0.9206928\n",
      "epoch :  43  -  cost:  0.25280645  - MSE:  4.362097894399136 - Train Accuracy:  0.92889696\n",
      "epoch :  44  -  cost:  0.24137829  - MSE:  4.364034810814653 - Train Accuracy:  0.93163174\n",
      "epoch :  45  -  cost:  0.22413264  - MSE:  4.369300302841354 - Train Accuracy:  0.9325433\n",
      "epoch :  46  -  cost:  0.2110134  - MSE:  4.367231716788891 - Train Accuracy:  0.93436646\n",
      "epoch :  47  -  cost:  0.18865825  - MSE:  4.363854778366337 - Train Accuracy:  0.94895166\n",
      "epoch :  48  -  cost:  0.16851906  - MSE:  4.378109955210957 - Train Accuracy:  0.9626253\n",
      "epoch :  49  -  cost:  0.15632822  - MSE:  4.366652595774826 - Train Accuracy:  0.9635369\n",
      "epoch :  50  -  cost:  0.14720461  - MSE:  4.3688451696386394 - Train Accuracy:  0.96718323\n",
      "epoch :  51  -  cost:  0.13884012  - MSE:  4.370735007811666 - Train Accuracy:  0.97356427\n",
      "epoch :  52  -  cost:  0.13218686  - MSE:  4.378643020329311 - Train Accuracy:  0.9753874\n",
      "epoch :  53  -  cost:  0.12568983  - MSE:  4.38697352108806 - Train Accuracy:  0.9790337\n",
      "epoch :  54  -  cost:  0.12019422  - MSE:  4.3975968384608874 - Train Accuracy:  0.9808569\n",
      "epoch :  55  -  cost:  0.114937745  - MSE:  4.40750823462158 - Train Accuracy:  0.9817685\n",
      "epoch :  56  -  cost:  0.10952148  - MSE:  4.418547773934481 - Train Accuracy:  0.9808569\n",
      "epoch :  57  -  cost:  0.10401613  - MSE:  4.430104636073591 - Train Accuracy:  0.9817685\n",
      "epoch :  58  -  cost:  0.09904309  - MSE:  4.443356866236772 - Train Accuracy:  0.98268\n",
      "epoch :  59  -  cost:  0.094777614  - MSE:  4.459889563264212 - Train Accuracy:  0.9845032\n",
      "epoch :  60  -  cost:  0.09101447  - MSE:  4.4757402957651635 - Train Accuracy:  0.98723793\n",
      "epoch :  61  -  cost:  0.087643944  - MSE:  4.492534483630581 - Train Accuracy:  0.98906106\n",
      "epoch :  62  -  cost:  0.08459063  - MSE:  4.509066340731706 - Train Accuracy:  0.98997265\n",
      "epoch :  63  -  cost:  0.08188229  - MSE:  4.5257190097837485 - Train Accuracy:  0.99088424\n",
      "epoch :  64  -  cost:  0.07951914  - MSE:  4.542846362618648 - Train Accuracy:  0.9917958\n",
      "epoch :  65  -  cost:  0.07734148  - MSE:  4.559166784601549 - Train Accuracy:  0.9927074\n",
      "epoch :  66  -  cost:  0.07533885  - MSE:  4.575583798950619 - Train Accuracy:  0.99361897\n",
      "epoch :  67  -  cost:  0.07351315  - MSE:  4.59197963395155 - Train Accuracy:  0.99361897\n",
      "epoch :  68  -  cost:  0.07182377  - MSE:  4.608216757100586 - Train Accuracy:  0.99361897\n",
      "epoch :  69  -  cost:  0.07025949  - MSE:  4.623991841088588 - Train Accuracy:  0.99361897\n",
      "epoch :  70  -  cost:  0.068768695  - MSE:  4.63934534123084 - Train Accuracy:  0.99361897\n",
      "epoch :  71  -  cost:  0.06733782  - MSE:  4.654495668872559 - Train Accuracy:  0.9954421\n",
      "epoch :  72  -  cost:  0.0660039  - MSE:  4.669331652469925 - Train Accuracy:  0.9954421\n",
      "epoch :  73  -  cost:  0.06476599  - MSE:  4.683841469397847 - Train Accuracy:  0.9954421\n",
      "epoch :  74  -  cost:  0.063609034  - MSE:  4.6980567432016205 - Train Accuracy:  0.9954421\n",
      "epoch :  75  -  cost:  0.06251976  - MSE:  4.712178175600235 - Train Accuracy:  0.9963537\n",
      "epoch :  76  -  cost:  0.0614939  - MSE:  4.726168471886397 - Train Accuracy:  0.9963537\n",
      "epoch :  77  -  cost:  0.060521837  - MSE:  4.74002063779365 - Train Accuracy:  0.9963537\n",
      "epoch :  78  -  cost:  0.059585225  - MSE:  4.753711299647609 - Train Accuracy:  0.9972653\n",
      "epoch :  79  -  cost:  0.058699742  - MSE:  4.767356898689271 - Train Accuracy:  0.9972653\n",
      "epoch :  80  -  cost:  0.05786162  - MSE:  4.780921926860778 - Train Accuracy:  0.9972653\n",
      "epoch :  81  -  cost:  0.057067446  - MSE:  4.794358279293972 - Train Accuracy:  0.9972653\n",
      "epoch :  82  -  cost:  0.05630947  - MSE:  4.807685624159393 - Train Accuracy:  0.9972653\n",
      "epoch :  83  -  cost:  0.05558579  - MSE:  4.820902761604723 - Train Accuracy:  0.9972653\n",
      "epoch :  84  -  cost:  0.054894775  - MSE:  4.834014581321413 - Train Accuracy:  0.9972653\n",
      "epoch :  85  -  cost:  0.054233454  - MSE:  4.847042981134316 - Train Accuracy:  0.9972653\n",
      "epoch :  86  -  cost:  0.05359819  - MSE:  4.8599326852314775 - Train Accuracy:  0.9972653\n",
      "epoch :  87  -  cost:  0.052987218  - MSE:  4.8726967083696 - Train Accuracy:  0.9972653\n",
      "epoch :  88  -  cost:  0.05239875  - MSE:  4.8853341800390435 - Train Accuracy:  0.9972653\n",
      "epoch :  89  -  cost:  0.051830824  - MSE:  4.897859214745536 - Train Accuracy:  0.9972653\n",
      "epoch :  90  -  cost:  0.051270485  - MSE:  4.910314736841432 - Train Accuracy:  0.9972653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  91  -  cost:  0.050730053  - MSE:  4.922680586064398 - Train Accuracy:  0.9972653\n",
      "epoch :  92  -  cost:  0.05020782  - MSE:  4.934957979270666 - Train Accuracy:  0.9972653\n",
      "epoch :  93  -  cost:  0.04970257  - MSE:  4.947150989420145 - Train Accuracy:  0.9972653\n",
      "epoch :  94  -  cost:  0.04921334  - MSE:  4.9592557352548825 - Train Accuracy:  0.9972653\n",
      "epoch :  95  -  cost:  0.048739128  - MSE:  4.971271089271929 - Train Accuracy:  0.9972653\n",
      "epoch :  96  -  cost:  0.04827903  - MSE:  4.983201572294714 - Train Accuracy:  0.9972653\n",
      "epoch :  97  -  cost:  0.047832303  - MSE:  4.995047143415143 - Train Accuracy:  0.9972653\n",
      "epoch :  98  -  cost:  0.04739833  - MSE:  5.006805567335866 - Train Accuracy:  0.9972653\n",
      "epoch :  99  -  cost:  0.0469766  - MSE:  5.018476817628565 - Train Accuracy:  0.9972653\n",
      "Model saved in file: C:\\Users\\raprabhu\\Downloads\\BankNotes\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  1.0\n",
      "MSE: 5.0185\n"
     ]
    }
   ],
   "source": [
    "# Define the encoder function.\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels, n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode\n",
    " \n",
    " \n",
    "# Read the dataset\n",
    "X, Y = read_dataset()\n",
    "\n",
    " \n",
    "# Shuffle the dataset to mix up the rows.\n",
    "X, Y = shuffle(X, Y, random_state=1)\n",
    " \n",
    "# Convert the dataset into train and test part\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size=0.20, random_state=415)\n",
    " \n",
    "# Inpect the shape of the training and testing.\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    " \n",
    "# Define the important parameters and variable to work with the tensors\n",
    "learning_rate = 0.3\n",
    "training_epochs = 100\n",
    "cost_history = np.empty(shape=[1], dtype=float)\n",
    "n_dim = X.shape[1]\n",
    "print(\"n_dim\", n_dim)\n",
    "n_class = 2\n",
    "model_path = \"C:\\\\Users\\\\raprabhu\\\\Downloads\\\\BankNotes\"\n",
    " \n",
    "# Define the number of hidden layers and number of neurons for each layer\n",
    "n_hidden_1 = 4\n",
    "n_hidden_2 = 4\n",
    "n_hidden_3 = 4\n",
    "n_hidden_4 = 4\n",
    " \n",
    "x = tf.placeholder(tf.float32, [None, n_dim])\n",
    "W = tf.Variable(tf.zeros([n_dim, n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    "y_ = tf.placeholder(tf.float32, [None, n_class])\n",
    " \n",
    " \n",
    "# Define the model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    " \n",
    "    # Hidden layer with RELU activationsd\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    " \n",
    "    # Hidden layer with sigmoid activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    " \n",
    "    # Hidden layer with sigmoid activation\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.relu(layer_3)\n",
    " \n",
    "    # Hidden layer with RELU activation\n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
    "    layer_4 = tf.nn.sigmoid(layer_4)\n",
    " \n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_4, weights['out']) + biases['out']\n",
    "    return out_layer\n",
    " \n",
    " \n",
    "# Define the weights and the biases for each layer\n",
    " \n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([n_dim, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3])),\n",
    "    'h4': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_4, n_class]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4': tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_class]))\n",
    "}\n",
    " \n",
    "# Initialize all the variables\n",
    " \n",
    "init = tf.global_variables_initializer()\n",
    " \n",
    "saver = tf.train.Saver()\n",
    " \n",
    "# Call your model defined\n",
    "y = multilayer_perceptron(x, weights, biases)\n",
    " \n",
    "# Define the cost function and optimizer\n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    " \n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    " \n",
    "# Calculate the cost and the accuracy for each epoch\n",
    " \n",
    "mse_history = []\n",
    "accuracy_history = []\n",
    " \n",
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step, feed_dict={x: train_x, y_: train_y})\n",
    "    cost = sess.run(cost_function, feed_dict={x: train_x, y_: train_y})\n",
    "    cost_history = np.append(cost_history, cost)\n",
    "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    # print(\"Accuracy: \", (sess.run(accuracy, feed_dict={x: test_x, y_: test_y})))\n",
    "    pred_y = sess.run(y, feed_dict={x: test_x})\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "    mse_ = sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy = (sess.run(accuracy, feed_dict={x: train_x, y_: train_y}))\n",
    "    accuracy_history.append(accuracy)\n",
    " \n",
    "    print('epoch : ', epoch, ' - ', 'cost: ', cost, \" - MSE: \", mse_, \"- Train Accuracy: \", accuracy)\n",
    " \n",
    "save_path = saver.save(sess, model_path)\n",
    "print(\"Model saved in file: %s\" % save_path)\n",
    " \n",
    "#Plot Accuracy Graph\n",
    "plt.plot(accuracy_history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    " \n",
    "# Print the final accuracy\n",
    " \n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Test Accuracy: \", (sess.run(accuracy, feed_dict={x: test_x, y_: test_y})))\n",
    " \n",
    "# Print the final mean square error\n",
    " \n",
    "pred_y = sess.run(y, feed_dict={x: test_x})\n",
    "mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "print(\"MSE: %.4f\" % sess.run(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original class: 754 Prediction values: [0] actual value [1. 0.]\n",
      "original class: 755 Prediction values: [1] actual value [0. 1.]\n",
      "original class: 756 Prediction values: [0] actual value [1. 0.]\n",
      "original class: 757 Prediction values: [0] actual value [1. 0.]\n",
      "original class: 758 Prediction values: [0] actual value [1. 0.]\n",
      "original class: 759 Prediction values: [0] actual value [1. 0.]\n",
      "original class: 760 Prediction values: [0] actual value [1. 0.]\n",
      "original class: 761 Prediction values: [0] actual value [1. 0.]\n",
      "original class: 762 Prediction values: [1] actual value [0. 1.]\n",
      "original class: 763 Prediction values: [1] actual value [0. 1.]\n",
      "original class: 764 Prediction values: [1] actual value [0. 1.]\n",
      "original class: 765 Prediction values: [1] actual value [0. 1.]\n",
      "original class: 766 Prediction values: [0] actual value [1. 0.]\n",
      "original class: 767 Prediction values: [0] actual value [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "prediction=tf.argmax(y,1)\n",
    "correct_prediction=tf.equal(prediction, tf.argmax(y_,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "\n",
    "for  i in range(754,768):\n",
    "    prediction_run=sess.run(prediction,feed_dict={x:X[i].reshape(1,4)}) \n",
    "    print(\"original class:\" , i,\"Prediction values:\", prediction_run, \"actual value\",Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
